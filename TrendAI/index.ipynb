{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrendAI\n",
    "\n",
    "#### The TrendAI feature uses Generative AI for image generation. The stable diffusion model is used to generate designs according to the prompts given. The inputs such as garment type, color, fabrice and trend are taken from the user. The output image generated based on these prompts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Installing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade diffusers transformers accelerate mediapy peft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up an image generation model and loading special weights to improve its performance.\n",
    "(Use GPU to get faster results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy as media\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from diffusers import DiffusionPipeline, TCDScheduler\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Choose either 8 or 12 steps:\n",
    "num_inference_steps = 12\n",
    "\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo_name = \"ByteDance/Hyper-SD\"\n",
    "plural = \"s\" if num_inference_steps > 1 else \"\"\n",
    "ckpt_name = f\"Hyper-SDXL-{num_inference_steps}step{plural}-CFG-lora.safetensors\"\n",
    "device = \"cuda\"\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16, variant=\"fp16\").to(device)\n",
    "pipe.load_lora_weights(hf_hub_download(repo_name, ckpt_name))\n",
    "pipe.fuse_lora()\n",
    "pipe.scheduler = TCDScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entering the prompt. The output image is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A long red satin dress\"\n",
    "seed = random.randint(0, sys.maxsize)\n",
    "\n",
    "# Pick a value between 5.0 and 8.0:\n",
    "guidance_scale = 5.0\n",
    "\n",
    "# Decrease eta (min: 0, max: 1.0) to get more details with multi-step inference:\n",
    "eta = 0.5\n",
    "\n",
    "images = pipe(\n",
    "    prompt = prompt,\n",
    "    num_inference_steps = num_inference_steps,\n",
    "    guidance_scale = guidance_scale,\n",
    "    eta = eta,\n",
    "    generator = torch.Generator(device).manual_seed(seed),\n",
    "    ).images\n",
    "\n",
    "print(f\"Prompt:\\t{prompt}\\nSeed:\\t{seed}\")\n",
    "media.show_images(images)\n",
    "images[0].save(\"output.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "https://github.com/woctezuma/stable-diffusion-colab"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
